# ğŸ§  AI Product Feedback Analyzer

> âœ¨ Summarize user/product feedback using local AI  
> ğŸ¤– Powered by **TinyLlama** via Ollama + Spring AI  
> ğŸ³ Fully **Dockerized** and **100% offline** â€” No API keys, No cloud, No limits

---

[![Java](https://img.shields.io/badge/Java-21-red?logo=java)](https://adoptium.net/)  
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.4.7-brightgreen?logo=springboot)](https://spring.io/projects/spring-boot)  
[![Spring AI](https://img.shields.io/badge/Spring--AI-1.0.0-purple?logo=spring)](https://docs.spring.io/spring-ai/)  
[![Ollama](https://img.shields.io/badge/Ollama-TinyLlama-yellow)](https://ollama.com)  
[![Dockerized](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://www.docker.com/)  
[![Local Only](https://img.shields.io/badge/LLM-100%25%20Offline-critical)](#)  
[![MIT License](https://img.shields.io/badge/License-MIT-lightgrey)](LICENSE)

---

## ğŸ§¾ What It Does

Give it user feedback like:

> â€œI love the design, but it crashes every time I try to share a photo.â€

It returns:

Summary: Crash issue during photo sharing.
Sentiment: Mixed (Positive UI, negative stability).
Suggested Action: Investigate crash on sharing functionality.


âœ”ï¸ **No JSON**  
âœ”ï¸ **Plain text insights**  
âœ”ï¸ **LLM-level summarization** without the cloud

---

## âš™ï¸ Tech Stack

| Layer         | Tech                        |
|---------------|-----------------------------|
| AI Model      | ğŸ§  TinyLlama (via Ollama)    |
| Prompt Engine | Spring AI 1.0.0             |
| Language      | â˜• Java 21                   |
| Framework     | Spring Boot 3.4.x           |
| Runtime       | ğŸ³ Docker & Docker Compose  |
| Output        | ğŸ“ Plain Text Only           |

---

## ğŸ§  How It Works

User Feedback â†’ Spring AI PromptTemplate â†’ ChatClient â†’ Ollama (TinyLlama) â†’ Insightful Summary


---

## ğŸ³ Run with Docker + Ollama

### ğŸ§± Prerequisites

- [Ollama](https://ollama.com/) installed and running
- [Docker](https://www.docker.com/) installed

### ğŸƒ Steps to Run

1. **Pull the model**  
```bash
ollama pull tinyllama

2. **Start the model server**
ollama run tinyllama

3. **Clone & run the app**
git clone https://github.com/vedant-gore/ai-feedback-analyzer.git
cd ai-feedback-analyzer
docker-compose up --build
